# ğŸ“ label_generator.py
# (æ­¤ä»£ç ä¸ä¸Šä¸€ä¸ªå›ç­”ä¸­æä¾›çš„ä¸€è‡´ï¼Œç”¨äº LLM å…·èº«æŒ‡ä»¤æ ‡æ³¨)

import json
import os
import argparse
from openai import OpenAI
import random
from typing import Dict, List

# --- é…ç½® ---
DATA_ROOT = "aerosight_data"
# âš ï¸ è¯·ç¡®ä¿æ‚¨çš„ OPENAI_API_KEY ç¯å¢ƒå˜é‡å·²è®¾ç½®
try:
    LLM_CLIENT = OpenAI() 
except:
    print("Warning: OpenAI client not initialized. Set OPENAI_API_KEY for labeling.")
    LLM_CLIENT = None
    
MODEL_NAME = "gpt-4-turbo"

# LLM æ ¸å¿ƒ Prompt (ç»“åˆ OpenFly VLN è§„èŒƒ)
INSTRUCTION_GENERATION_PROMPT = """
ä½ æ˜¯ä¸€åé«˜çº§çš„è§†è§‰-è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰æŒ‡ä»¤ç”Ÿæˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æ— äººæœºçš„ç²¾ç¡®è½¨è¿¹ä¿¡æ¯ã€å§¿æ€ä¿¡æ¯ä»¥åŠæ²¿é€”çš„è¯­ä¹‰è§‚æµ‹ï¼Œé€†å‘æ¨å¯¼å‡ºä¸€æ¡è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚è¿™æ¡æŒ‡ä»¤å¿…é¡»èƒ½å¤Ÿè®© VLA æ¨¡å‹åœ¨åŒæ ·çš„åœºæ™¯ä¸­ï¼Œç²¾ç¡®åœ°å¤ç°è¿™æ¡è½¨è¿¹ã€‚

---
**VLN æŒ‡ä»¤æ ¼å¼è§„èŒƒ (OpenFly æ ‡å‡†):**
1.  **å†…å®¹æ ¼å¼ï¼š** å¿…é¡»ç”± **åœ°æ ‡ (Landmark)** + **åŠ¨ä½œåºåˆ— (Action Sequence)** æ„æˆã€‚
2.  **é•¿åº¦çº¦æŸï¼š** é™åˆ¶åœ¨ **1 åˆ° 3 ä¸ª** è¿ç»­çš„çŸ­ç¨‹åŠ¨ä½œæ­¥éª¤ã€‚ä½¿ç”¨ 'Then', 'Next', 'Finally' ç­‰è¿æ¥è¯ä¸²è”æ­¥éª¤ã€‚
3.  **å‚ç…§æ–¹å¼ï¼š** å¿…é¡»åŒ…å«å½“å‰è§†é‡å†…ç‰©ä½“çš„ **ç›¸å¯¹ä½ç½®** å’Œ **è§†è§‰å±æ€§**ã€‚åœ°æ ‡å¿…é¡»ä½¿ç”¨é¢œè‰²ã€å¤§å°ã€å½¢çŠ¶ã€çª—å£ç±»å‹ç­‰è§†è§‰å±æ€§è¯¦ç»†æè¿°ã€‚

**è¾“å…¥ä¿¡æ¯ (æ¥è‡ªè½¨è¿¹å…ƒæ•°æ®å’Œè¯­ä¹‰åˆ†æ):**
- è½¨è¿¹èµ·ç‚¹å’Œç»ˆç‚¹çš„ç²¾ç¡® NED åæ ‡ã€‚
- æ²¿é€”é‡‡é›†åˆ°çš„å…³é”®è¯­ä¹‰åœ°æ ‡å’Œè§†è§‰å±æ€§ï¼ˆè¿™äº›ä¿¡æ¯ä»£è¡¨äº† VLA æ¨¡å‹çš„è§†è§‰è§‚æµ‹ï¼‰ã€‚
- è½¨è¿¹æ‰§è¡Œçš„åŠ¨ä½œæ‘˜è¦ï¼ˆæ–¹å‘å’Œè·ç¦»ï¼‰ã€‚

**ä»»åŠ¡ï¼š** åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€æ¡ç¬¦åˆ VLN è§„èŒƒçš„æŒ‡ä»¤ã€‚

**ç¤ºä¾‹ï¼ˆå¿…è¯»ï¼‰ï¼š**
- Trajectory: [Start: Tree-A, End: Building-B] -> [Action: Forward, Yaw Right, Forward]
- Semantic Clues: Tall Green Tree (A), Large Brown Building (B) with Rectangular Windows.
- **Output Instruction:** "Proceed in a straight line toward the large brown building with rectangular windows . Then , slightly turn right and advance forward to the large brown building with rectangular windows . Finally , continue straight to the gray office building with horizontal window blinds ."

---
**è¯·ä¸¥æ ¼éµå¾ªè§„èŒƒï¼Œä»…è¾“å‡ºä¸€æ¡æŒ‡ä»¤ï¼Œä¸è¦åŒ…å«ä»»ä½• Thought æˆ–å…¶ä»–è§£é‡Šã€‚**
"""

def generate_vln_instruction(trajectory_context: Dict[str, Any]) -> str:
    """è°ƒç”¨ LLM API ç”Ÿæˆ VLN æŒ‡ä»¤ã€‚"""
    if LLM_CLIENT is None:
        return "LLM_ERROR: Client not ready. Check API key."

    start_pos = trajectory_context['start_pose']['position']
    end_pos = trajectory_context['end_pose']['position']
    
    start_pos_str = f"Start NED: ({start_pos[0]:.2f}, {start_pos[1]:.2f}, {start_pos[2]:.2f})"
    end_pos_str = f"End NED: ({end_pos[0]:.2f}, {end_pos[1]:.2f}, {end_pos[2]:.2f})"
    
    # âš ï¸ å®é™…éœ€è¦å®ç°ä¸€ä¸ªå‡½æ•°æ¥åˆ†ææ²¿é€”çš„è¯­ä¹‰åˆ†å‰²å›¾å’Œå…³é”®å¸§ï¼Œæå–åœ°æ ‡æè¿°ã€‚
    # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåŒ…å«æ‰°åŠ¨çš„éšæœºå ä½ç¬¦ï¼Œæ¨¡æ‹Ÿè¯­ä¹‰åˆ†æçš„ç»“æœã€‚
    mock_semantic_clues = random.choice([
        "Identified a large red warehouse and a tall yellow crane near the start point.",
        "Passed several small green trees and a white circular tank.",
        "The path involved a left turn near a small blue container and ended near a building with blue glass windows."
    ])
    
    user_message = f"""
    - Trajectory ID: {trajectory_context['traj_id']}
    - Pose: {start_pos_str} to {end_pos_str}
    - Key Semantic Clues Found Along Path (VLM/LMM Analysis): {mock_semantic_clues}
    - Action Sequence Summary (Based on Chunk Analysis): [Forward 15m, Slightly Yaw Left, Advance 5m]
    """
    
    try:
        response = LLM_CLIENT.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": INSTRUCTION_GENERATION_PROMPT},
                {"role": "user", "content": user_message}
            ],
            temperature=0.7 
        )
        # ç¡®ä¿è¾“å‡ºæ˜¯å¹²å‡€çš„æŒ‡ä»¤
        return response.choices[0].message.content.strip().replace('\n', ' ')
    except Exception as e:
        return f"LLM_ERROR: Failed to generate instruction: {e}"

def main():
    # ... (ä¸ä¸Šä¸€ä¸ªå›ç­”ä¸­çš„ main å‡½æ•°ä¿æŒä¸€è‡´)
    parser = argparse.ArgumentParser(description="AeroSight LLM-based VLN Label Generator.")
    parser.add_argument("--scene_name", type=str, required=True, help="Name of the AirSim scene to process.")
    args = parser.parse_args()
    
    scene_path = os.path.join(DATA_ROOT, args.scene_name)
    metadata_path = os.path.join(scene_path, "trajectories_metadata.jsonl")

    if not os.path.exists(metadata_path):
        print(f"Error: Metadata file not found at {metadata_path}. Please run data_collector.py first.")
        return

    labeled_data = []
    has_unlabeled = False
    
    with open(metadata_path, 'r') as f:
        lines = f.readlines()
        
    for line in lines:
        meta = json.loads(line)
        if meta.get("is_labeled") != "SUCCESS":
            has_unlabeled = True
            print(f"-> Generating instruction for {meta['traj_id']}...")
            instruction = generate_vln_instruction(meta)
            
            meta["vln_instruction"] = instruction
            meta["is_labeled"] = "SUCCESS" if not instruction.startswith("LLM_ERROR") else "FAILED"
            print(f"   [Result]: {instruction[:80]}...")
        
        labeled_data.append(meta)

    if not has_unlabeled:
        print("All trajectories already labeled. Skipping generation.")

    # ä¿å­˜æ›´æ–°åçš„å…ƒæ•°æ®æ–‡ä»¶
    with open(metadata_path, 'w') as f:
        for meta in labeled_data:
            f.write(json.dumps(meta) + '\n')
    
    print("\nLabel generation finished. Check the updated metadata.jsonl file.")

if __name__ == "__main__":
    main()