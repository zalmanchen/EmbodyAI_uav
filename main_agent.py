import json
import time
from typing import List, Dict, Any

# --- å¯¼å…¥æ ¸å¿ƒç»„ä»¶ ---
from airsim_client import AirSimClient 
from uav_tools.flight_controls import fly_to_gps, move_forward, set_yaw
from uav_tools.vision_bridge import capture_and_analyze_rgb
from llm_agent_core.memory_manager import MemoryManager
from llm_agent_core.prompt_templates import CORE_SYSTEM_PROMPT, TOOL_SCHEMAS 

# --- å¯¼å…¥ OpenFly VLA æ¨¡æ‹Ÿå·¥å…· ---
# å‡è®¾è¿™æ˜¯ OpenFly VLA æ¨¡å‹çš„æ‰§è¡Œæ¥å£
from uav_tools.flight_controls import execute_vln_instruction 

# ğŸ“ main_agent.py (å…³é”®ä¿®æ”¹éƒ¨åˆ†)

# ... å¯¼å…¥è¯­å¥ ...

# --- å¯¼å…¥ flight_controls çš„ CLIENT BINDER ---
from uav_tools.flight_controls import set_airsim_client # <--- æ–°å¯¼å…¥

# --- åˆå§‹åŒ–å…¨å±€å·¥å…·å’Œå®¢æˆ·ç«¯ ---

# 1. å®¢æˆ·ç«¯å’Œè¿æ¥ 
AIRSIM_CLIENT = AirSimClient(vehicle_name="Drone1")
if not AIRSIM_CLIENT.connect_and_initialize():
    print("FATAL ERROR: AirSim è¿æ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡ºã€‚")
    exit()

# ************ æ–°å¢çš„å…³é”®æ­¥éª¤ ************
# å°† AirSimClient å®ä¾‹ç»‘å®šåˆ° flight_controls æ¨¡å—
set_airsim_client(AIRSIM_CLIENT) 
# ****************************************


# 2. è®°å¿†ç®¡ç†å™¨
MEMORY_MANAGER = MemoryManager()

# 3. å¯ç”¨çš„å·¥å…·å‡½æ•°æ˜ å°„
# æ³¨æ„ï¼šæˆ‘ä»¬ç°åœ¨å°† execute_vln_instruction è§†ä¸º LLM å¯ç›´æ¥è°ƒç”¨çš„å·¥å…·
AVAILABLE_TOOLS = {
    "takeoff": AIRSIM_CLIENT.takeoff,
    "land": AIRSIM_CLIENT.land,
    "get_current_pose": AIRSIM_CLIENT.get_current_pose,
    "fly_to_gps": fly_to_gps,
    "move_forward": move_forward,
    "set_yaw": set_yaw,
    "capture_and_analyze_rgb": capture_and_analyze_rgb,
    "update_search_map": MEMORY_MANAGER.update_search_map,
    "retrieve_historical_clues": MEMORY_MANAGER.retrieve_historical_clues,
    "execute_vln_instruction": execute_vln_instruction,  # <--- VLA æ‰§è¡Œå·¥å…·
    "report_finding": lambda coords, desc: f"REPORT: å‘ç°ç›®æ ‡äº {coords}ã€‚è¯¦æƒ…: {desc}"
}

# --- æ¨¡æ‹Ÿ LLM æ¥å£ (åŒå±‚ Agent æ¨¡æ‹Ÿ) ---

def mock_llm_call(messages: List[Dict[str, Any]], schemas: Dict[str, Any]) -> Dict[str, Any]:
    """
    ã€æ¨¡æ‹Ÿå‡½æ•°ã€‘æ›¿ä»£çœŸå®çš„ LLM API è°ƒç”¨ã€‚
    æ¨¡æ‹Ÿ LLM ä½œä¸ºé«˜çº§è§„åˆ’è€…ï¼Œå†³å®šæ˜¯è¿›è¡Œå®è§‚é£è¡Œè¿˜æ˜¯å¯åŠ¨ VLA å¯¼èˆªã€‚
    """
    # è·å–å¯¹è¯å†å²ä¸­æœ€æ–°çš„è§‚å¯Ÿç»“æœ
    last_observation = messages[-1]['content'] if messages[-1]['role'] != 'system' else ""
    
    # è·å– LLM çš„å½“å‰çŠ¶æ€
    step = len(messages) // 2 # ç²—ç•¥ä¼°è®¡æ­¥éª¤æ•° (ç³»ç»Ÿæ¶ˆæ¯ + Nä¸ª(LLMè¡ŒåŠ¨ + å·¥å…·è§‚å¯Ÿ))
    
    # --- æ¨¡æ‹Ÿé«˜çº§è§„åˆ’é€»è¾‘ ---
    
    # 1. åˆå§‹é˜¶æ®µï¼šèµ·é£
    if "æœªçŸ¥" in messages[0]['content'] and "takeoff" not in last_observation:
        print("MOCK LLM: åˆå§‹é˜¶æ®µï¼Œå†³å®šèµ·é£...")
        return {
            "role": "assistant",
            "thought": "ä»»åŠ¡å¼€å§‹ï¼Œé¦–å…ˆéœ€è¦èµ·é£åˆ°å®‰å…¨é«˜åº¦ 20 ç±³ã€‚",
            "tool_calls": [{"id": "mock_id_1", "function": {"name": "takeoff", "arguments": '{"altitude": 20.0}'}}]
        }
    
    # 2. èµ·é£åçš„ç¬¬ä¸€æ­¥ï¼šè·å–å§¿æ€å¹¶è§„åˆ’å®è§‚é£è¡Œ
    elif "èµ·é£æˆåŠŸ" in last_observation and "get_current_pose" not in [m.get('tool_calls', [{}])[0].get('function', {}).get('name') for m in messages]:
        print("MOCK LLM: å·²èµ·é£ï¼Œå†³å®šè·å–å½“å‰ä½ç½®...")
        return {
            "role": "assistant",
            "thought": "èµ·é£å®Œæˆï¼Œä¸‹ä¸€æ­¥æ˜¯è·å–å½“å‰ç²¾ç¡®ä½ç½®ï¼Œç”¨äºè§„åˆ’å‰å¾€ç›®æ ‡åŒºåŸŸçš„å®è§‚è·¯å¾„ã€‚",
            "tool_calls": [{"id": "mock_id_2", "function": {"name": "get_current_pose", "arguments": "{}"}}]
        }
        
    # 3. å®è§‚é£è¡Œåˆ°æœç´¢åŒºåŸŸ
    elif last_observation.startswith("OBSERVATION: å½“å‰å§¿æ€") and step < 3:
        print("MOCK LLM: å·²çŸ¥ä½ç½®ï¼Œè§„åˆ’å®è§‚é£è¡Œåˆ°ç›®æ ‡åŒºåŸŸ...")
        # å‡è®¾ç›®æ ‡åŒºåŸŸåœ¨ (47.6418, -122.14)
        return {
            "role": "assistant",
            "thought": "å·²è·å–å½“å‰ä½ç½®ï¼Œç°åœ¨è§„åˆ’é£å¾€æœç´¢åŒºåŸŸ (47.6418, -122.14) çš„ä¸Šç©º 30 ç±³ã€‚",
            "tool_calls": [{"id": "mock_id_3", "function": {"name": "fly_to_gps", "arguments": '{"latitude": 47.6418, "longitude": -122.14, "altitude_meters": 30.0}'}}]
        }
    
    # 4. åˆ°è¾¾åŒºåŸŸåï¼šå¯åŠ¨ VLA ä½çº§æ‰§è¡Œ
    elif "æˆåŠŸé£æŠµç›®æ ‡åæ ‡" in last_observation:
        print("MOCK LLM: å·²åˆ°è¾¾å®è§‚æœç´¢åŒºåŸŸï¼Œå¯åŠ¨ OpenFly VLA è¿›è¡Œç²¾ç»†æœç´¢...")
        # LLM ç°åœ¨ä¸ç›´æ¥è°ƒç”¨ Vision å·¥å…·ï¼Œè€Œæ˜¯è°ƒç”¨ VLA æ‰§è¡Œå™¨
        vln_instruction = "åœ¨å‘¨å›´å¯»æ‰¾çº¢è‰²çš„èƒŒåŒ…ï¼Œå¹¶é è¿‘åˆ° 3 ç±³ä»¥å†…ã€‚"
        return {
            "role": "assistant",
            "thought": f"å®è§‚é£è¡Œå®Œæˆï¼Œç°åœ¨å°†æ§åˆ¶æƒäº¤ç»™ VLA æ¨¡å‹ï¼Œæ‰§è¡Œç²¾ç»†çš„è§†è§‰å¯¼èˆªæŒ‡ä»¤ï¼š'{vln_instruction}'ã€‚",
            "tool_calls": [{"id": "mock_id_4", "function": {"name": "execute_vln_instruction", "arguments": json.dumps({"language_instruction": vln_instruction})}}]
        }
    
    # 5. VLA æ‰§è¡Œå®Œæˆï¼šæ£€æŸ¥ç»“æœå¹¶æŠ¥å‘Š
    elif "VLA æ¨¡å‹å·²å®Œæˆå¯¼èˆªæŒ‡ä»¤" in last_observation:
        print("MOCK LLM: VLA ä»»åŠ¡å®Œæˆï¼Œæ¨¡æ‹Ÿç›®æ ‡å‘ç°ï¼Œå†³å®šæŠ¥å‘Šå¹¶é™è½...")
        coords = "Lat: 47.6417, Lon: -122.1401, Alt: 27.0m" # å‡è®¾ VLA æ‰¾åˆ°äº†æ›´ç²¾ç¡®çš„ä½ç½®
        return {
            "role": "assistant",
            "thought": f"VLA æŠ¥å‘Šå·²å®Œæˆç²¾ç»†æœç´¢ï¼Œç›®æ ‡å·²ç¡®è®¤åœ¨ {coords}ã€‚ç«‹å³æŠ¥å‘Šå¹¶è¿”å›é™è½ã€‚",
            "tool_calls": [
                {"id": "mock_id_5a", "function": {"name": "report_finding", "arguments": json.dumps({"coordinates": coords, "description": "é«˜åº¦å¯ä¿¡çš„çº¢è‰²ç›®æ ‡ç‰©ï¼Œç–‘ä¼¼å¤±è¸ªè€…èƒŒåŒ… (VLA ç¡®è®¤)"})}},
                {"id": "mock_id_5b", "function": {"name": "land", "arguments": "{}"}}
            ]
        }
    
    # 6. é»˜è®¤ï¼šæœªå‘ç°/æµç¨‹ç»“æŸ
    else:
        return {"role": "assistant", "content": "ä»»åŠ¡æµç¨‹æ¼”ç¤ºå®Œæ¯•ï¼Œè¯·æ‰‹åŠ¨é‡ç½®æˆ–æä¾›æ–°çš„æŒ‡ä»¤ã€‚"}


# --- ä¸»å¾ªç¯é©±åŠ¨å™¨ (ä¿æŒä¸å˜ï¼Œä½†ä½¿ç”¨æ›´æ–°åçš„ Prompt) ---

def run_agent(initial_goal: str):
    """é©±åŠ¨ LLM-Agent çš„ä¸»å¾ªç¯ï¼šæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿã€‚"""
    
    # 1. åˆå§‹åŒ–å¯¹è¯å†å²å’Œç³»ç»Ÿ Prompt (ä½¿ç”¨æ¨¡å—åŒ–æ¨¡æ¿)
    system_prompt = CORE_SYSTEM_PROMPT.format(
        initial_goal=initial_goal,
        current_pose="æœªçŸ¥"
    )
    messages = [{"role": "system", "content": system_prompt}]
    
    print("="*60)
    print(f"Agent ä¸»å¾ªç¯å¯åŠ¨ | åˆå§‹ç›®æ ‡: {initial_goal}")
    print("="*60)
    
    max_steps = 10
    step_count = 0
    
    while step_count < max_steps:
        print(f"\n--- æ­¥éª¤ {step_count + 1}ï¼šè§„åˆ’é˜¶æ®µ ---")
        
        # 2. LLM è§„åˆ’ & è¡ŒåŠ¨ (Function Call)
        llm_response = mock_llm_call(messages, TOOL_SCHEMAS)
        
        # è¾“å‡º LLM çš„æ€è€ƒè¿‡ç¨‹
        if llm_response.get("thought"):
            print(f"âœ… Agent æ€è€ƒ: {llm_response['thought']}")
        
        # 3. æ‰§è¡Œå·¥å…·
        if llm_response.get("tool_calls"):
            tool_calls = llm_response["tool_calls"]
            messages.append(llm_response) 
            
            tool_outputs = []
            
            for tool_call in tool_calls:
                function_name = tool_call["function"]["name"]
                try:
                    function_args = json.loads(tool_call["function"]["arguments"])
                    print(f"   -> è°ƒç”¨å·¥å…·: {function_name} ({function_args})")
                    
                    function_to_call = AVAILABLE_TOOLS.get(function_name)
                    if function_to_call:
                        # 4. æ‰§è¡Œ & è§‚å¯Ÿ
                        observation = function_to_call(**function_args)
                    else:
                        observation = f"ERROR: æœªæ‰¾åˆ°å·¥å…·å‡½æ•° {function_name}"
                        
                except Exception as e:
                    observation = f"EXECUTION ERROR: å·¥å…· {function_name} æ‰§è¡Œå¤±è´¥: {e}"
                
                print(f"   <- è§‚å¯Ÿç»“æœ (Observation): {observation[:100]}...")
                
                # 5. å°†è§‚å¯Ÿç»“æœåé¦ˆç»™ LLM
                tool_outputs.append({
                    "role": "tool", 
                    "tool_call_id": tool_call["id"], 
                    "content": observation
                })
            
            messages.extend(tool_outputs) 
        
        # 6. LLM ç»™å‡ºæœ€ç»ˆæŠ¥å‘Š (ç»“æŸä»»åŠ¡)
        elif llm_response.get("content"):
            print(f"\n--- ä»»åŠ¡ç»“æŸ ---")
            print(f"Agent æœ€ç»ˆæŠ¥å‘Š: {llm_response['content']}")
            break
            
        step_count += 1
        time.sleep(1) 

    if step_count >= max_steps:
        print("\nè¾¾åˆ°æœ€å¤§æ‰§è¡Œæ­¥æ•°é™åˆ¶ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
    
    # æœ€ç»ˆæ¸…ç† (å¦‚æœåœ¨å¾ªç¯ä¸­æ²¡æœ‰é™è½)
    AIRSIM_CLIENT.land()

if __name__ == "__main__":
    # è¿è¡Œ Agent ä»»åŠ¡
    run_agent("å»åæ ‡ (47.6418, -122.14) é™„è¿‘çš„åŒºåŸŸï¼Œå¯»æ‰¾çº¢è‰²çš„æ ‡è®°ç‰©æˆ–å¤±è¸ªè€…ã€‚")
